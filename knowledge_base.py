"""
RAGçŸ¥è¯†åº“ç®¡ç†æ¨¡å— - åŸºäºFAISSå‘é‡æ•°æ®åº“ (è½»é‡çº§æ–¹æ¡ˆ)
"""
import os
import json
import pickle
from datetime import datetime
from typing import List, Dict, Optional
import numpy as np

try:
    import faiss
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… faiss: pip install faiss-cpu")
    exit(1)

from langchain_google_genai import GoogleGenerativeAIEmbeddings
from config import Config


class SupplierKnowledgeBase:
    """ä¾›åº”å•†çŸ¥è¯†åº“ - åŸºäºFAISSå‘é‡æ•°æ®åº“"""

    def __init__(self, persist_directory: str = "data/knowledge_base"):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“

        Args:
            persist_directory: æ•°æ®åº“æŒä¹…åŒ–ç›®å½•
        """
        self.persist_directory = persist_directory
        self.index_path = os.path.join(persist_directory, "faiss.index")
        self.metadata_path = os.path.join(persist_directory, "metadata.json")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(persist_directory, exist_ok=True)

        # åˆå§‹åŒ–Google Embeddings
        # ä½¿ç”¨text-embedding-004ï¼ˆæœ€æ–°ç¨³å®šç‰ˆæœ¬ï¼‰
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/gemini-embedding-001",
            google_api_key=Config.GOOGLE_API_KEY
        )

        # å‘é‡ç»´åº¦ï¼ˆtext-embedding-004 æ˜¯ 768ç»´ï¼‰
        self.dimension = 768

        # åŠ è½½æˆ–åˆ›å»ºç´¢å¼•
        self._load_or_create_index()

        print(f"âœ… çŸ¥è¯†åº“åˆå§‹åŒ–æˆåŠŸ")
        print(f"   å­˜å‚¨ä½ç½®: {persist_directory}")
        print(f"   å½“å‰ä¾›åº”å•†æ•°: {len(self.suppliers)}")

    def _load_or_create_index(self):
        """åŠ è½½æˆ–åˆ›å»ºFAISSç´¢å¼•"""

        if os.path.exists(self.index_path) and os.path.exists(self.metadata_path):
            # åŠ è½½ç°æœ‰ç´¢å¼•
            self.index = faiss.read_index(self.index_path)

            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                self.suppliers = json.load(f)

            print(f"   âœ… åŠ è½½ç°æœ‰ç´¢å¼•: {len(self.suppliers)} ä¸ªä¾›åº”å•†")
        else:
            # åˆ›å»ºæ–°ç´¢å¼•
            self.index = faiss.IndexFlatL2(self.dimension)  # L2è·ç¦»
            self.suppliers = []

            print(f"   âœ… åˆ›å»ºæ–°ç´¢å¼•")

    def add_supplier(self, supplier: Dict) -> bool:
        """
        æ·»åŠ ä¾›åº”å•†åˆ°çŸ¥è¯†åº“

        Args:
            supplier: ä¾›åº”å•†ä¿¡æ¯å­—å…¸

        Returns:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            # æ„å»ºæ–‡æ¡£å†…å®¹ï¼ˆç”¨äºå‘é‡åŒ–ï¼‰
            content = self._build_document_content(supplier)

            # å‘é‡åŒ–
            embedding = self.embeddings.embed_query(content)
            embedding_array = np.array([embedding]).astype('float32')

            # æ·»åŠ åˆ°FAISSç´¢å¼•
            self.index.add(embedding_array)

            # ä¿å­˜å…ƒæ•°æ®
            metadata = self._build_metadata(supplier)
            self.suppliers.append(metadata)

            print(f"  âœ… å·²æ·»åŠ : {supplier.get('title', 'Unknown')[:50]}")

            # æŒä¹…åŒ–
            self._save_index()

            return True

        except Exception as e:
            print(f"  âŒ æ·»åŠ å¤±è´¥: {e}")
            return False

    def add_suppliers_batch(self, suppliers: List[Dict]) -> int:
        """
        æ‰¹é‡æ·»åŠ ä¾›åº”å•†ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

        Args:
            suppliers: ä¾›åº”å•†åˆ—è¡¨

        Returns:
            int: æˆåŠŸæ·»åŠ çš„æ•°é‡
        """
        print(f"\nğŸ“š æ‰¹é‡æ·»åŠ ä¾›åº”å•†åˆ°çŸ¥è¯†åº“...")

        success_count = 0
        embeddings_to_add = []
        metadata_to_add = []

        for i, supplier in enumerate(suppliers, 1):
            print(f"  [{i}/{len(suppliers)}]", end=" ")

            try:
                # æ„å»ºæ–‡æ¡£å†…å®¹
                content = self._build_document_content(supplier)

                # å‘é‡åŒ–
                embedding = self.embeddings.embed_query(content)
                embeddings_to_add.append(embedding)

                # å…ƒæ•°æ®
                metadata = self._build_metadata(supplier)
                metadata_to_add.append(metadata)

                print(f"âœ… {supplier.get('title', 'Unknown')[:30]}")
                success_count += 1

            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")

        # æ‰¹é‡æ·»åŠ åˆ°FAISS
        if embeddings_to_add:
            embeddings_array = np.array(embeddings_to_add).astype('float32')
            self.index.add(embeddings_array)
            self.suppliers.extend(metadata_to_add)

            # æŒä¹…åŒ–
            self._save_index()

        print(f"\nâœ… æ‰¹é‡æ·»åŠ å®Œæˆ: {success_count}/{len(suppliers)}")

        return success_count

    def search_suppliers(
            self,
            query: str,
            k: int = 5,
            min_similarity: float = 0.5
    ) -> List[Dict]:
        """
        è¯­ä¹‰æœç´¢ä¾›åº”å•†

        Args:
            query: æœç´¢æŸ¥è¯¢ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            k: è¿”å›ç»“æœæ•°é‡
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼Œè·ç¦»è½¬æ¢åï¼‰

        Returns:
            List[Dict]: åŒ¹é…çš„ä¾›åº”å•†åˆ—è¡¨
        """
        try:
            if len(self.suppliers) == 0:
                return []

            # æŸ¥è¯¢å‘é‡åŒ–
            query_embedding = self.embeddings.embed_query(query)
            query_array = np.array([query_embedding]).astype('float32')

            # FAISSæœç´¢ï¼ˆè¿”å›è·ç¦»ï¼Œä¸æ˜¯ç›¸ä¼¼åº¦ï¼‰
            # L2è·ç¦»ï¼šè¶Šå°è¶Šç›¸ä¼¼
            distances, indices = self.index.search(query_array, min(k, len(self.suppliers)))

            # è½¬æ¢ä¸ºä¾›åº”å•†åˆ—è¡¨
            results = []
            for distance, idx in zip(distances[0], indices[0]):
                if idx < len(self.suppliers):
                    supplier = self.suppliers[idx].copy()

                    # è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ (0-1)
                    # ä½¿ç”¨exp(-distance/10)ä½œä¸ºç›¸ä¼¼åº¦ï¼Œè·ç¦»è¶Šå°ç›¸ä¼¼åº¦è¶Šé«˜
                    similarity = np.exp(-distance / 10)
                    supplier["similarity_score"] = round(float(similarity), 3)
                    supplier["distance"] = round(float(distance), 3)

                    # è¿‡æ»¤ä½ç›¸ä¼¼åº¦
                    if similarity >= min_similarity:
                        results.append(supplier)

            return results

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []

    def get_all_suppliers(self) -> List[Dict]:
        """è·å–æ‰€æœ‰ä¾›åº”å•†"""
        return self.suppliers.copy()

    def get_statistics(self) -> Dict:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""

        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        categories = {}
        statuses = {}

        for supplier in self.suppliers:
            category = supplier.get("category", "æœªåˆ†ç±»")
            status = supplier.get("cooperation_status", "æœªè”ç³»")

            categories[category] = categories.get(category, 0) + 1
            statuses[status] = statuses.get(status, 0) + 1

        return {
            "total_count": len(self.suppliers),
            "categories": categories,
            "cooperation_status": statuses,
            "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

    def _save_index(self):
        """ä¿å­˜ç´¢å¼•åˆ°ç£ç›˜"""
        try:
            faiss.write_index(self.index, self.index_path)

            with open(self.metadata_path, 'w', encoding='utf-8') as f:
                json.dump(self.suppliers, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")

    def _build_document_content(self, supplier: Dict) -> str:
        """æ„å»ºç”¨äºå‘é‡åŒ–çš„æ–‡æ¡£å†…å®¹"""

        # æå–å…³é”®ä¿¡æ¯
        company_name = supplier.get("title", "")
        category = supplier.get("category", "")
        snippet = supplier.get("snippet", "")
        reason = supplier.get("reason", "")
        match_type = supplier.get("match_type", "")

        # æ‹¼æ¥æˆè‡ªç„¶è¯­è¨€æè¿°
        content_parts = [
            f"å…¬å¸åç§°: {company_name}",
            f"ç±»åˆ«: {category}",
            f"ç±»å‹: {match_type}",
            f"æè¿°: {snippet}",
            f"è¯„ä»·: {reason}"
        ]

        content = "\n".join([p for p in content_parts if p])

        return content

    def _build_metadata(self, supplier: Dict) -> Dict:
        """æ„å»ºå…ƒæ•°æ®"""

        contact = supplier.get("contact", {})

        metadata = {
            "company_name": supplier.get("title", "Unknown"),
            "category": supplier.get("category", "ç”µå­äº§å“"),
            "website": supplier.get("link", ""),
            "match_type": supplier.get("match_type", ""),
            "supplier_score": supplier.get("score", 0),
            "contact_person": contact.get("name", ""),
            "email": contact.get("email", ""),
            "phone": contact.get("phone", ""),
            "linkedin": contact.get("linkedin", ""),
            "cooperation_status": "æœªè”ç³»",
            "add_date": datetime.now().strftime("%Y-%m-%d"),
            "source": supplier.get("source", "Googleæœç´¢")
        }

        return metadata


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()

    print("=" * 60)
    print("æµ‹è¯•ä¾›åº”å•†çŸ¥è¯†åº“ (FAISSç‰ˆæœ¬)")
    print("=" * 60)

    try:
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        kb = SupplierKnowledgeBase()

        # æµ‹è¯•æ•°æ®
        test_supplier = {
            "title": "Shenzhen Test Electronics Co., Ltd.",
            "link": "https://www.test.com",
            "snippet": "Professional Bluetooth headphone manufacturer with CE certification",
            "match_type": "åˆ¶é€ å•†",
            "score": 90,
            "reason": "ä¸“ä¸šTWSè€³æœºå·¥å‚",
            "category": "æ¶ˆè´¹ç”µå­",
            "contact": {
                "name": "John Zhang",
                "title": "Sales Director",
                "email": "john@test.com",
                "phone": "+86-123-4567"
            }
        }

        # æµ‹è¯•æ·»åŠ 
        print("\nã€æµ‹è¯•1: æ·»åŠ ä¾›åº”å•†ã€‘")
        kb.add_supplier(test_supplier)

        # æµ‹è¯•æœç´¢
        print("\nã€æµ‹è¯•2: è¯­ä¹‰æœç´¢ã€‘")
        results = kb.search_suppliers("è“ç‰™è€³æœºåˆ¶é€ å•†", k=3, min_similarity=0.3)

        print(f"\næ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
        for i, supplier in enumerate(results, 1):
            print(f"\n{i}. {supplier['company_name']}")
            print(f"   ç›¸ä¼¼åº¦: {supplier['similarity_score']}")
            print(f"   è·ç¦»: {supplier['distance']}")
            print(f"   é‚®ç®±: {supplier['email']}")

        # æµ‹è¯•ç»Ÿè®¡
        print("\nã€æµ‹è¯•3: ç»Ÿè®¡ä¿¡æ¯ã€‘")
        stats = kb.get_statistics()
        print(f"\næ€»ä¾›åº”å•†æ•°: {stats['total_count']}")
        print(f"ç±»åˆ«åˆ†å¸ƒ: {stats['categories']}")

        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()